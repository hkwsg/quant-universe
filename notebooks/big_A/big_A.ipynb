{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from pathlib import Path\n",
    "ROOT_DIR=Path(os.getcwd()).parent.parent\n",
    "if not str(ROOT_DIR) in sys.path:\n",
    "    sys.path.append(str(ROOT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from src.data.equity_data.tradingview import BigA\n",
    "biga = BigA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks, etfs, foreign_etf = biga.load_data_cache_from_csv(dt='2024-01-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 SQL 格式读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db_path = ROOT_DIR / 'database' / 'China_A_Share.db'\n",
    "conn = sqlite3.connect(db_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从本地SQL数据库读取所有数据用时:  54.75 秒\n"
     ]
    }
   ],
   "source": [
    "# read data from database and time profling\n",
    "start = time.time()\n",
    "history_data = pd.read_sql(\"SELECT * FROM history_quote\", conn)\n",
    "end = time.time()\n",
    "print('从本地SQL数据库读取所有数据用时: ', round(end - start,2), '秒')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据大小为:  (13768777, 13)\n"
     ]
    }
   ],
   "source": [
    "print(\"数据大小为: \", history_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 pickle 文件格式读写数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle文件大小为1.49GB\n",
      "写入pickle文件耗时10.94秒\n",
      "读取pickle文件耗时4.35秒\n"
     ]
    }
   ],
   "source": [
    "pickle_file_path = ROOT_DIR/'data'/ 'equity_market' / '2_equity_hist_price' / 'a_share_hist_price.pickle'\n",
    "\n",
    "start = time.time()\n",
    "history_data.to_pickle(pickle_file_path)\n",
    "end = time.time()\n",
    "load_time_pickle = end - start\n",
    "\n",
    "# the size of the pickle file in GB\n",
    "import os\n",
    "size_pickle=round(os.path.getsize(pickle_file_path)/1024/1024/1024, 2)\n",
    "\n",
    "# load the pickle file, and profile the time\n",
    "start = time.time()\n",
    "history_data_from_pickle = pd.read_pickle(pickle_file_path)\n",
    "end = time.time()\n",
    "read_time_pickle = end - start\n",
    "\n",
    "print(f\"pickle文件大小为{size_pickle}GB\")\n",
    "print(f\"写入pickle文件耗时{round(load_time_pickle, 2)}秒\")\n",
    "print(f\"读取pickle文件耗时{round(read_time_pickle, 2)}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 Parquet 文件格式读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parquet文件大小为0.33GB\n",
      "写入parquet文件耗时4.84秒\n",
      "读取parquet文件耗时1.11秒\n"
     ]
    }
   ],
   "source": [
    "file_path_parquet=ROOT_DIR/'data'/ 'equity_market' / '2_equity_hist_price' / 'a_share_hist_price.parquet' \n",
    "\n",
    "# write to parquet file with time profiling\n",
    "start = time.time()\n",
    "history_data.to_parquet(file_path_parquet)\n",
    "end = time.time()\n",
    "load_time_parquet = end - start\n",
    "\n",
    "# get the size of the file in GB\n",
    "size_parquet=round(os.path.getsize(file_path_parquet)/1024/1024/1024, 2)\n",
    "\n",
    "# read the parquet file with time profiling\n",
    "start = time.time()\n",
    "history_data_from_parquet = pd.read_parquet(file_path_parquet)\n",
    "end = time.time()\n",
    "read_time_parquet = end - start\n",
    "\n",
    "print(f\"parquet文件大小为{size_parquet}GB\")\n",
    "print(f\"写入parquet文件耗时{round(load_time_parquet, 2)}秒\")\n",
    "print(f\"读取parquet文件耗时{round(read_time_parquet, 2)}秒\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用 xarray 读写 NetCDF 格式文件\n",
    "xarray是一个Python库，旨在为处理多维数组数据提供强大的工具和数据结构。它特别适用于处理科学数据，例如气象数据、地理信息系统（GIS）数据、气候模拟和地球科学数据等。xarray的主要功能包括：\n",
    "\n",
    "- 数据数组：xarray引入了DataArray数据结构，允许您轻松管理多维数组数据，并为每个维度和坐标轴提供描述性标签。\n",
    "- 数据集：Dataset是xarray的另一个关键数据结构，它可以容纳多个DataArray，使您能够组织和分析复杂的数据集。\n",
    "- 坐标轴标签：xarray允许您为每个维度添加可描述性的标签，这使得数据处理更加直观和易于理解。\n",
    "- 灵活的数据索引：您可以使用坐标轴标签轻松访问和切片数据，而不需要手动计算索引位置。\n",
    "- 内置的统计和计算功能：xarray提供了许多内置函数，用于执行各种统计和数学运算，使数据分析更加方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf文件大小为1.42GB\n",
      "写入netcdf文件耗时15.4秒\n",
      "读取netcdf文件耗时0.17秒\n"
     ]
    }
   ],
   "source": [
    "netcdf_file_path = ROOT_DIR / 'data' / 'equity_market' / '2_equity_hist_price' / 'a_share_hist_price.nc'\n",
    "\n",
    "# write to netcdf file with time profiling\n",
    "start = time.time()\n",
    "history_data_xarray = history_data.rename(\n",
    "    columns={\n",
    "        '股票名称': 'stock_name',\n",
    "        '股票代码': 'ticker',\n",
    "        '日期': 'date',\n",
    "        '开盘': 'open',\n",
    "        '收盘': 'close',\n",
    "        '最高': 'high',\n",
    "        '最低': 'low',\n",
    "        '成交量': 'volume',\n",
    "        '成交额': 'volume*price',\n",
    "        '振幅': 'amplitude',\n",
    "        '涨跌幅': 'change_pct',\n",
    "        '涨跌额': 'change',\n",
    "        '换手率': 'turnover'\n",
    "    }\n",
    ").to_xarray()\n",
    "history_data_xarray.to_netcdf(netcdf_file_path)\n",
    "end = time.time()\n",
    "load_time_netcdf = end - start\n",
    "\n",
    "# get the size of the file in GB\n",
    "size_netcdf=round(os.path.getsize(netcdf_file_path)/1024/1024/1024, 2)\n",
    "\n",
    "# read the netcdf file with time profiling\n",
    "start = time.time()\n",
    "import xarray as xr\n",
    "history_data_from_netcdf = xr.open_dataset(netcdf_file_path)\n",
    "end = time.time()\n",
    "read_time_netcdf = end - start\n",
    "\n",
    "print(f\"netcdf文件大小为{size_netcdf}GB\")\n",
    "print(f\"写入netcdf文件耗时{round(load_time_netcdf, 2)}秒\")\n",
    "print(f\"读取netcdf文件耗时{round(read_time_netcdf, 2)}秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newworld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
